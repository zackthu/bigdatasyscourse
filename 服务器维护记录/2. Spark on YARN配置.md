

1. spark-shell.sh

```sh
export SPARK_MASTER_HOST=192.168.0.101   #设定MASTER节点的IP

export SPARK_WORKER_CORES=32   #设定每台主机上使用的核心数
export SPARK_WORKER_MEMORY=32g   #设定每台主机上使用的内存大小

export SPARK_EXECUTOR_CORES=1   #每个用户进程执行单位
export SPARK_EXECUTOR_MEMORY=1g  #每个执行单位使用的内存
export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native   #添加这个避免Spark启动出错
```


2. spark-defaults.conf

```sh
spark.ui.reverseProxy true   #设定代理，用户可以从外部查看任务运行信息（没有开启这个会出现http://192.168.0.10x:40xx这种地址，这种地址因路由器NAT无法从外网访问）
spark.ui.killEnabled false  #禁止用户在控制也没关闭进程，由于控制也没没有做用户认证，因此关闭这个选项

#每个用户进程连接会占用一个端口，如果用户连接数过多（比如实验课上），那么后面连接的用户会逐个测试新端口，尝试maxRetries次后没找到就会报错，因此需要将这个参数设置成一个较大的值
spark.port.maxRetries=200
```


3. slaves
```
thumm02
thumm03
thumm04
thumm05
thumm06
```