
Hadoop的配置文件存放在$HADOOP_HOME/etc/hadoop文件夹下, 需要配置的文件主要有
- hadoop-env.sh
- core-site.xml
- hdfs-site.xml
- yarn-site.xml
- mapred-site.xml

接下来对这几个文件的配置做一些说明。 

1. hadoop-env.sh
该文件用于配置hadoop的环境变量, 下面是现在hadoop-env.sh的内容:
```sh
export HADOOP_SHELL_EXECNAME=root
export HDFS_DATANODE_USER=root
export HDFS_DATANODE_SECURE_USER=hadoop
export HDFS_NAMENODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
```

2. core-site.xml

```xml
<configuration>
<property>
    <name>fs.defaultFS</name>   <!-- 指定NameNode位置，这里指定NameNode在一号节点上 -->
    <value>hdfs://thumm01:9000</value>
</property>
<property>
    <name>hadoop.tmp.dir</name> <!-- 指定tmp文件夹，不设置可能会出错(具体错误忘记了) -->
    <value>/mnt/data/hadoop/tmp</value>
</property>
<property>
    <name>hadoop.security.authorization</name>  <!-- 开启用户认证，避免用户访问其他用户数据 -->
    <value>true</value>
</property>
</configuration>
```


3. hdfs-site.xml

```xml
<configuration>
<property>   
    <name>dfs.replication</name>  <!-- 每个数据块被存放的数量 -->
    <value>3</value>
</property>

<property>
    <name>dfs.namenode.http-address</name>  <!-- 第一个NameNode的访问入口，指定主机和端口 -->
    <value>thumm01:9870</value>
</property>
<property>
    <name>dfs.namenode.secondary.http-address</name>  <!-- 第二个NameNode的访问入口，指定主机和端口 -->
    <value>thumm06:9868</value>
</property>

<property>
    <name>dfs.datanode.data.dir</name>      <!-- 配置DataNode数据存放的位置，由于服务器的系统磁盘很小，数据不能放在默认位置，需要指定到另一个大容量的磁盘(/dev/sdb1)，这个磁盘挂在在了/mnt/data处 -->
    <value>/mnt/data/hadoop/hdfs/data</value>
</property>

<property>
    <name>dfs.namenode.name.dir</name>     <!-- 配置NameNode数据存放位置，理由同上 -->
    <value>/mnt/data/hadoop/hdfs/name</value>
</property>

<property>
    <name>dfs.cluster.administrators</name>   <!-- 配置管理员名称 -->
    <value>root</value>
</property>
<property>
```


4. mapred-site.xml

```xml
<configuration>
<property>
    <name>mapreduce.framework.name</name>    <!-- 配置mapreduce框架，必填-->
    <value>yarn</value>
</property>
<property>
    <name>mapreduce.application.classpath</name>  <!-- 配置classpath, 不配置会出现运行WordCount时卡在map:100%, reduce:0% 的阶段-->
    <value>
        $HADOOP_HOME/etc/hadoop,
        $HADOOP_HOME/hadoop/common/*,
        $HADOOP_HOME/share/hadoop/common/lib/*,
        $HADOOP_HOME/share/hadoop/hdfs/*,
        $HADOOP_HOME/share/hadoop/hdfs/lib/*,
        $HADOOP_HOME/share/hadoop/mapreduce/*,
        $HADOOP_HOME/share/hadoop/mapreduce/lib/*,
        $HADOOP_HOME/share/hadoop/yarn/*,
        $HADOOP_HOME/share/hadoop/yarn/lib/*
    </value>
</property>
</configuration>
```

5. yarn-site.xml

```xml
<configuration>
<property>
    <name>yarn.resourcemanager.hostname</name>   <!-- 指定yarn的ResourceManager运行的位置-->
    <value>thumm01</value>
</property>
<property>
    <name>yarn.nodemanager.aux-services</name>  <!-- 这个都是这么填的 -->
    <value>mapreduce_shuffle</value>
</property>
<property>
    <name>yarn.nodemanager.resource.cpu-vcores</name>  <!-- 配置nodemanager虚拟CPU资源数，这里使用32核心，因为是vcore，不是真实核心数，因此可以写得比真是核心数大 -->
    <value>32</value>
</property>
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>  <!-- 配置nodemanager内存资源数，这里使用32GB， 内存这不能比真实内存大（机器内存有64GB） -->
    <value>32768</value>
</property>
<property>
    <name>yarn.scheduler.maximum-allocation-mb</name>  <!-- 同上 -->
    <value>32768</value>
</property>
<property>
    <name>yarn.resourcemanager.bind-host</name>    <!-- 这个如果不设置它默认绑定127.0.0.1, 那么只能在内主机内查看资源管理网页，而设置成0.0.0.0， 就能从外网访问(需要用ufw allow 端口号 开启对应的端口) -->
    <value>0.0.0.0</value>
</property>
</configuration>
```